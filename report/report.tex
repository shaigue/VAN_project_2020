\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}

\title{VAN final project report}
\date{2020-05-01}
\author{Shai Guendelman, Avnom Hanohov}

\begin{document}
	% this is how to comment with '%'
	% this produces the title in a single front page
	\maketitle
	\newpage
	
	% sections, subsections, and subsubsections are of 
	% different topics.
	% paragraphes and subparagraphes are not numbered
	% this is a section with latex examples. delete this before 
	% final draft, but keep to use as referance
	\section{Latex examples section - delete after}
	\subsection{this is a subsection}
	sum subsection stuff 
	
	\paragraph{this is unnumbered paragrapha, can go anywere}
	some staff
	\subsubsection{you can even go 2 levels down}
	\paragraph{even here!}
	paragraph. you can force line-down with \\
	down!
	\\
	you can put anywere in the text some math by using the $$double dollar$$ or $dollar$ sign use inline math \\
	you can also do numbered equations:
	\begin{equation}
	x=y
	\end{equation}
	or un-numbered equations:
	\begin{equation*}
	x=y
	\end{equation*}
	if you want to stack equations on top of each other, and align them, you can use the "align" and "align*" for unnumbered, and each line will be aligned so that the '\&' symbol will be under the first eq.
	\begin{align}
	shai&=present \\
	potato&=tapud	
	\end{align}
	examples for subscript, superscript, fraction, sqrt and integral:
	\begin{align*}
	a &= x^2 \\
	b &= x_1^2 + x_{i_1}^{j_2} \\
	c &= a - x_j \\ 
	d &= \int p(x)xdx \\
	f &= \frac{num}{den} \\
	s &= \sqrt{2}
	\end{align*}
	we can add brakets that hold a certain object and size:
	\begin{equation*}
	\left[
	\begin{matrix}
	11 & 12 & 13 \\
	21 & 22 & 23 \\
	31 & 32 & 33
	\end{matrix}
	\right]
	\end{equation*}
	or :
	\begin{equation*}
	\left(
	\begin{matrix}
	11 & 12 & 13 \\
	21 & 22 & 23 \\
	31 & 32 & 33
	\end{matrix}
	\right)
	\end{equation*}
	Greek letters usually with writing their name: $\lambda$ with small first letter for lower case, and for upper case use $\Lambda$ with upper case first letter
	\\
	this is enough for now, want to learn more go to https://www.latex-tutorial.com/tutorials/figures/ 
	to continue\\
	
	\section{Introduction and overview}
	% TODO: Introduce the paper(s) topic. Describe how the paper fits in with the contents of this course, provide a brief background (literature review) and explain why the problem is important
	\section{Preliminary material and problem formulation}
	% TODO: Present a description of relevant notations and definitions, define mathematically the problem addressed by the paper(s), and summarize any preliminary mathematical material used in the paper(s).
	In this Work we deal we address 2 papers written on the subject of \textbf{Active sensing and Observation Correlation Modelling},
	we will split our discussion to the 2 papers, paper (1) will refer to \textbf{Observation Modelling for Vision-Based Target Search by Unmanned Aerial Vehicles}, and paper (2) will refer to \textbf{Modelling Observation Correlation for Active Exploration and Robust Object Detection}.
	\subsection{paper (1)}
	
	\subsubsection{Notations and definitions}
	
	\begin{itemize}
		\item $\mathcal{G}$ - We divide our search area into grid-cells. This is the set of all the cells.
		\item $g \in \mathcal{G}$ - A single grid cell.
		\item $\delta_g$ - A RV that represents does cell $g$ has an object in it? $\delta_g = 1$ is yes, $\delta_g = 0$ is no. 
		\item $\mathcal{Z} \subset \mathbb{R}^3$ - This is the sub-space that the drone is allowed to travel in. 
		\item $t \in \mathbb{N}$ - Time, in desecrate steps.	
		\item $z_t \in \mathcal{Z}$ - this is the 3D location of the drone at time $t$.
		\item $G_t \subset \mathcal{G}$ - this is the subset of all the observed grid-cells at time $t$.
		\item $s_g^t \in \mathbb{R}$ - Score that the classifier produced about an object being in cell $g$ observed at time $t$.   
		\item $d^t_g = (s_g^t, z_t)$ - A data point, this is a tuple of a measurement(classifier score of cell $g$), at time $t$, and the drone's position at that time.
		\item $D_g^t = \{d_g^r|r \leq t\}$, $D^t=\{D_g^t|g\in\mathcal{G}\}$ - The set of all the observations obtained about grid cell $g$ until(including) time $t$. 
		\item $\Delta = \{\delta_g|g\in\mathcal{G}\}$ - Joint RV of all the grid cells occupancy.
		\item $D^{+t},D^{-t}$ - 2 additional notations, the $-$ refers to all of the data-points up until time $t$, and $+$ refers to the future data-points that will be collected up until some finite time $t'$ in the future.
	\end{itemize}

	\subsubsection{Problem definition}
	The aim of this article is to estimate the probability of finding some object(for example, a victim in a search and rescue mission) in a given location in space. It tries to so without assuming that different observation of the same location are independent of each other. We split the search area to grid cells - $\mathcal{G}$, transforming it to an estimation problem of a finite number of random variables - the probability for each $g \in \mathcal{G}$ to contain an object $\delta_g$, given all the past observations of this specific grid cell until time $t$, $D_g^t$, i.e. estimating $p(\delta_g|D_g^t)$. And to update that belief given new observation of the same grid cell $d_g^{t_1}$ on some time in the future, $t_1>t$. \\
	
	We need to consider how to model the correlation between different observations of the same object. The paper assumes independence between different grid cells.
	To improve our estimation we need to choose a path such that the overall uncertainty of the scene will be minimized.
	Uncertainty is described as conditional Entropy, $H(\Delta|D^t)$, which measures how much $\Delta$ is uncertain, after acquiring data-points. The path that we take will determine the observations obtained, and thus the posterior $p(\Delta|D^t)$. This motivates us to plan the trajectory such that $H(\Delta|D^t)$ will be minimized.
	
	\subsection{Paper (2)}
	\subsubsection{Notations and definitions}
	\begin{itemize}
		\item $x^i$ - The 2D pose of the robot in at time $i$,
		$x^i \in \mathbb{R}^2 \times SO(2)$ where $SO(2)$ denotes the orientation.
		\item $x^{0:k}$ - The robot's trajectory form times $0$ to $k$.
		\item $c_{mot}(x^{0:k})$ - The cost associated with the motion along a trajectory(time, fuel, other operational costs).
		\item $y_i, Y_i, (u_i, v_i)$ - $Y_i$ is an object hypothesis, in location $(u_i, v_i)$,
		$y_i$ is it's value. $Y_i$ is a binary random variable in the range $\{object,no-object\}$
		\item $a_i$ - A \textbf{Decision action}. $a_i\in\{accept,reject\}$ that represents our decision on object hypothesis $Y_i$. 
		\item $\xi_{dec}$ - \textbf{Decision Cost} function for accepting or rejecting the object hypothesis, based on it's true value.
		$\xi_{dec} : \{accept,reject\}\times\{object,no-object\}\rightarrow\mathbb{R}$ 
		\item $Q$ - this is the number of object hypothesis in the scene.
		\item $\pi$ - this is the plan, a trajectory and decision actions $\{x^{0:k},a_{0:Q}\}$.
		\item $c_{det}(x^{0:k},a_{0:Q})$ - The Expectation of decision costs $\xi_{dec}(a_i,y_i)$, based on the belief we have over $Y$ (the joint of all $Y_i$) after traveling through trajectory $x^{0:k}$.
		\begin{equation}
		c_{det}(x^{0:k},a_{1:Q})=\mathbb{E}_{y|x^{0:k}}[\xi_{dec}(a_{1:Q},y)]
		\end{equation}  
		It is a way to estimate the total decision cost, we need this for planning, because we do not have access to the ground truth about the true value of $Y$.
		\item $z^k$ - the observation obtained in time $k$ from view point $x^k$. (big $Z$ refers to the Random Variable). The domain is not specified in the paper, could be some classifier score, or something else.
		\item $\mathcal{T}^k = {(x^1,z^1),...,(x^k,z^k)}$ - this is the history of all view point and observations pairs.
		\item $\Psi$ - Symbol for the environment's RV necessary for accurately model the sensor's observation generation.
		\item $\alpha = z^k \perp \mathcal{T}^{k-1}$ - RV that means "is the k'th observation correlated with the history of observations?"
	\end{itemize}
	\subsubsection{Problem formulation}
	The goal is:
	given a start and an end point,
	find the optimal plan, $\pi=(x^{0:k},a_{1:Q})$, that minimizes the total cost function:
	\begin{equation}
	\pi^* = \underset{\pi}{argmin}[c_{mot}(x^{0:k}) + c_{dec}(x^{0:k},a^{1:Q})]
	\end{equation}
	[to simplify, we will write $a$ instead of $a_{1:Q}$ and the same for $Y,y$]
	
	To do so we need a way to model the posterior $Y|X^{0:k}$, both \textbf{(a)} after we have the available data, i.e. the history of measurements from time 0 to k -$\mathcal{T}^k$, to estimate the current belief,
	and \textbf{(b)} a way to generate future measurements to estimate how the postirior will change after taking the trajectory.
	
	\textbf{(a)} can be formulated by:
	\begin{equation}
	p(Y|\mathcal{T}^k)
	\end{equation}
	
	\textbf{(b)} can be formulated by obtaining the generative model:
	\begin{equation}
	p(Z^k|X^k,\mathcal{T}^{0:k-1})
	\end{equation}
	
	To do so we assume that different object hypothesis are independent. In this article we don't assume that the different observations are conditionally independent given the robot's state(as we do in the course). To have conditional independence we need additional information about the environment(like lighting, occlusions, ...) denoted by $\Psi$, and fully modeling that is intractable. Instead we want a way to model correlation between current and past observations:
	
	\begin{equation}
	p(z^k|y,x^k,\Psi) \approx p(z^k|y,x^k,\mathcal{T}^{k-1})
	\end{equation}
	
	Another issue that has to be addressed is computation time. All of this should be done online, and the most computationally intensive task at hand is the planning stage. Because the we don't assume that observations are independent of each other, the problem is not a "Markov Chain" (as assumed in the course), thus trying to solve as an explicit POMDP model will be computationally complex. We need to develop an efficient method to sample future trajectories(forward search, instead of considering all possible options), and propagate the belief accordingly, such that the resulting plan will too far from the real optimal plan.
	
	\subsection{Mathematical material used in the papers}
	\begin{itemize}
		\item Gaussian Process - The Mathematical definition of a Gaussian Process (GP) is:
		 a set of R.V.'s $\{X_i\}_{i \in I}$ such that for every finite subset $J \subseteq I$, $\{X_i\}_{i \in J}$ is multivariate normal.
		 Here it is used as a method for modeling. This is done by assuming that all of the sampled data is distributed as a GP, with some covariance and mean kernel functions that given the index of the R.V. 
		 (e.g., if the R.V. is $X_t$ then the index is $t$), we can have the mean and covariance. for example: \\
		 Let $I=[0,\inf]$ indicate the time, and ${X_i} \sim \mathcal{GP}(m(\cdot), k(\cdot,\cdot))$, so for each finite set of time-points
		 $\{X_{t_1},X_{t_2},...,X_{t_n}\} \sim N(\mu,\Sigma)$ , and the mean and covariance are determined by the kernel functions 
		 $m$ and $k$, such that $\mu_i = m(t_i)$, and $\Sigma_{i,j} = k(t_i, t_j)$. We can use the GP to predict the value of $X_t$ when we have known data-points $\{x_{t_1},x_{t_2},...,x_{t_n}\}$  by considering the joint distribution of $\{X_{t_1},X_{t_2},...,X_{t_n},X_t\}$, 
		 and then using Schur's compliment to get the conditional distribution $p(X_t|X_{t_1},X_{t_2},...,X_{t_n})$, and estimate the mean and uncertainty(covariance) of $X_t|data$.
		\item Some Information Theory concepts - 
		
		\textbf{Entropy} - given a R.V. $X$, its Entropy $H(X)$ is given by $H(X)=E[-log(p(X))]$. It is a measure of how unpredictable a R.V. is. \\ 
		
		\textbf{Conditional Entropy} - $H(X|Y)$  this is the same as entropy, just now it is for the conditioned R.V., also fallows the formula $H(X,Y)=H(X|Y) + H(Y)$, and means "the Entropy of $X$ after we have know $Y$".
		This relation always holds: $H(X|Y) \leq H(X)$. \\
		  
		\textbf{Mutual Information} - $I(X;Y)$, it is defined as $I(X;Y)=\mathbb{E}\left[log\frac{p(x,y)}{p(x)p(y)}\right]$ it is  a measure of how informative the state of $Y$ is with respect to $X$ (it is symmetric). If $X,Y$ are independent, it will be 0, otherwise it will be strictly positive.
		It also always holds that: $I(X;Y)=H(X)-H(X|Y)$, This means that the M.I. is the difference of how unpredictable $X$ is without and with knowing $Y$.  
		
		\item \textbf{MSDE} - Mean Squared Detection Error - used for evaluating the estimations result's in paper[1].
		
		$$MSDE = \frac{1}{|\mathcal{G}|}\sum_{g \in \mathcal{G}}[\delta_g - P(\delta_g = 1|D_g^t)]^2 $$		
	\end{itemize}
	
	% math formulation of the problems
	% extra math things
	\section{Main contribution}
	% TODO: A detailed discussion of the main results of the paper(s). This should include both a qualitative discussion and a mathematical presentation (i.e. show proofs, preferably in your own style).
	\section{Implementation}
	% TODO: Demonstrate the main results of the paper(s) using simulation and/or real-world experiments. You are free to choose the programming language as well as using open source software. This also includes testing the approaches under different conditions than those originally assumed in the paper(s), as well as extending approaches to unsupported settings/scenarios.
	
	\section{Discussion and Conclusions}
	% TODO: Summarize the report and provide some criticism: identify weak points, unrealistic assumptions or aspects that could be improved and suggest possible directions (or extensions) for future research
	\subsection{Summery}
	In this report we examined 2 articles written on the subjects `active exploration` and `observation correlation modeling`,
	in the context of robust object detection. From the papers results we can clearly see that it is beneficial in terms of classification accuracy to consider (a) the planning aspect, by including in the objective function(that defines our optimal plan) a term that relates to the uncertainty in the class estimations, and (b) in integrating new observation, while not assuming that observations are completely independent given the robot's state. Both papers give some rough models that can be used for this, but probably too simplistic at their current form.
	
	
	\subsection{Criticism}
	*\textbf{Model Training} - both papers train their models on data that is very simmilar to that that they test on, 
	which is not optimal, as we cannot expect to have training data available of every environment, and each environment has it's own specific correlations model. This is some how true in paper [1], but there only the parameters of the GP are learned, so this model can generalize more easily, but in paper [2] the resulting model is higly fitted to a spacific enfironment, and will not generalize to an environmanet that does not resamble the original one. they do not offer a way to train or to use such a model when we do not have available labeled training data on the environemnt which we will operate in. 	
	
	\subsection{Notes and Future Research}
	
	*\textbf{First of all} We want to incorporate what that we have learned in the course and the papers, and draw some conclusions.
	In the papers, the SLAM problem is assumed to be perfectly solved. That is usually not the case, we still have some uncertainty about the robot and object's locations, and that also increases the level of uncertainty in the classification with this method, because we use the robot's location in modeling the correlation, so when our location has some uncertainty, this will add to the total uncertainty of the problem.
	
	Another problem that we need to deal with, is that when our location and the object's relative location is uncertain, this will eventually lead to data association problems, i.e. thinking that 2 different object hypothesis are comming from the same object, - this might lead to the wrong classification of at least one object(if they are not of the same class), with high uncertainty, even if the actual classifier preformed perfectly.
	
	or oppisite, that we think that one object is actually 2 differnt ones, this will lead to at least one false positive result.
	
	in the contrary, if we do not assume that SLAM is solved while traiying to takle this problem, we can benefit from that.
	by incorporaing all the observations, including the observed object's and their classes, we gain another layer of information to our optimization problem, this will give us more information to check if our matches are correct, and to better estimating loop closers(accepting or rejecting), by using the extra information from class that might match or not. 
	
	the active exploration part can also be used to reduce uncertainty in the SLAM part of the problem.
	
	this also can lead to the problem descussed in the next part, when the robot hypothesises that nearby cells are with the same object, and we assume independence between near by cell, but if the localization is not known, different cells can get signals from the same object, that because of drifts is sometimes estimated to be in one cell, and the next time in a near by cell.
	
	*both papers assume that \textbf{different object hypothesis / grid cells are uncorrelated}, and only assume correlations between different observations of the same object / grid cell. even that it is usually not the case, in search and rescue it is reasonable to assume that victims should be nearby, that text will be clustered in space, and that a computer, a keyboard and a chair will probably come together, or as explained above, the same object might appear twice as 2 different objects due to bad data association, and we need to think how might we merge this 2 different hypothesis in the future if we gather more information that gets us better localization. it might be valuable not to neglect this correlation.
	
	*\textbf{decisions are independent of path planning} - paper [2] assume that the decision actions(deciding is there an object in some place or not) is independent on the path planning, and could be done in the end of the process. but what if there beeing or not being an objects in a certain spot does relate to the motion planning? (like if the objects are things that we want to avoid like land mines, or things that have meaning about the way we should plan like traffic signs, or determinme the objective, like finding a halipad to land on?)
		
	% TODO: look at how to add refrences
	
	% TODO: how to reference equations
	
  
\end{document}
